{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendations in pytorch using triplet loss\n",
    "Along the lines of BPR [1]. \n",
    "\n",
    "[1] Rendle, Steffen, et al. \"BPR: Bayesian personalized ranking from implicit feedback.\" Proceedings of the Twenty-Fifth Conference on Uncertainty in Artificial Intelligence. AUAI Press, 2009.\n",
    "\n",
    "This is implemented (more efficiently) in LightFM (https://github.com/lyst/lightfm). See the MovieLens example (https://github.com/lyst/lightfm/blob/master/examples/movielens/example.ipynb) for results comparable to this notebook.\n",
    "\n",
    "## Set up the architecture\n",
    "A simple dense layer for both users and items: this is exactly equivalent to latent factor matrix when multiplied by binary user and item indices. There are three inputs: users, positive items, and negative items. In the triplet objective we try to make the positive item rank higher than the negative item for that user.\n",
    "\n",
    "Because we want just one single embedding for the items, we use shared weights for the positive and negative item inputs (a siamese architecture).\n",
    "\n",
    "This is all very simple but could be made arbitrarily complex, with more layers, conv layers and so on. I expect we'll be seeing a lot of papers doing just that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import itertools\n",
    "import data\n",
    "import metrics\n",
    "from time import time\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from functools import partial\n",
    "from itertools import chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "944 1683\n"
     ]
    }
   ],
   "source": [
    "n_latent = 20\n",
    "batch_size = 64\n",
    "\n",
    "# Read data\n",
    "train, test = data.get_movielens_data()\n",
    "train = train.tocsr()\n",
    "n_users, n_items = train.shape\n",
    "print(n_users, n_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FactNet(nn.Module):\n",
    "    def __init__(self,\n",
    "                 n_users, n_items,\n",
    "                 n_latent,\n",
    "                ):\n",
    "        super(FactNet, self).__init__()\n",
    "        self.n_users = n_users\n",
    "        self.n_items = n_items\n",
    "        self.n_latent = n_latent\n",
    "        self.user_embedding_layer = nn.Embedding(self.n_users, self.n_latent)\n",
    "        self.item_embedding_layer = nn.Embedding(self.n_items, self.n_latent)  # both pos and neg items share these params\n",
    "        init.uniform(self.user_embedding_layer.weight, -0.5, 0.5)\n",
    "        init.uniform(self.item_embedding_layer.weight, -0.5, 0.5)  # default was normal\n",
    "        \n",
    "    def predict_score(self, uid, iid):\n",
    "        user_embedding = self.user_embedding_layer(uid)\n",
    "        item_embedding = self.item_embedding_layer(iid)\n",
    "        score = (user_embedding * item_embedding).sum(dim=1)\n",
    "        return score\n",
    "    \n",
    "        \n",
    "    def forward(self, uid, pid, nid):\n",
    "        # lulzy forward for loss computation\n",
    "        user_embedding = self.user_embedding_layer(uid)\n",
    "        pos_item_embedding = self.item_embedding_layer(pid)\n",
    "        neg_item_embedding = self.item_embedding_layer(nid)\n",
    "        \n",
    "        # torch.dot doesnt take in axis :sadface:\n",
    "        pos_pred = (user_embedding * pos_item_embedding).sum(dim=1)\n",
    "        neg_pred = (user_embedding * neg_item_embedding).sum(dim=1)\n",
    "        return pos_pred, neg_pred\n",
    "\n",
    "    \n",
    "class TripletLoss(nn.Module):\n",
    "    def __init__(self, loss='hinge', warp_weighting=True, n_items=None):\n",
    "        super(TripletLoss, self).__init__()\n",
    "        self.n_items = n_items\n",
    "        loss_d = {\n",
    "            'sigmoid': self.forward_sigmoid,\n",
    "            'hinge': self.forward_hinge,\n",
    "        }\n",
    "        if warp_weighting:\n",
    "            self.forward_premean = lambda pos_pred, neg_pred, nsamp: \\\n",
    "                self.warp_weight(nsamp) * loss_d[loss](pos_pred, neg_pred)\n",
    "        else:\n",
    "            self.forward_premean = lambda pos_pred, neg_pred, nsamp: \\\n",
    "                loss_d[loss](pos_pred, neg_pred)\n",
    "        \n",
    "    def forward(self, *args):\n",
    "        return self.forward_premean(*args).mean()\n",
    "        \n",
    "    def warp_weight(self, nsamp):\n",
    "        return torch.log(torch.floor((self.n_items-1)/nsamp)) / np.log(self.n_items)\n",
    "    \n",
    "    def forward_sigmoid(self, pos_pred, neg_pred):\n",
    "        loss = 1.0 - torch.sigmoid(pos_pred - neg_pred)\n",
    "        return loss\n",
    "    \n",
    "    def forward_hinge(self, pos_pred, neg_pred):\n",
    "        loss = torch.clamp(1.0 + neg_pred - pos_pred, min=0.0)\n",
    "        return loss\n",
    "\n",
    "\n",
    "net = FactNet(n_users, n_items, n_latent)\n",
    "criterion = TripletLoss(loss='hinge', warp_weighting=True, n_items=n_items)\n",
    "# optimizer = optim.Adam(net.parameters())\n",
    "# optimizer = optim.Adadelta(net.parameters())\n",
    "optimizer = optim.Adagrad(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batcher(iterable, batch_size):\n",
    "    it = iter(iterable)\n",
    "    while True:\n",
    "        chunk = tuple(itertools.islice(it, batch_size))\n",
    "        if not chunk:\n",
    "            return\n",
    "        yield np.array(chunk, dtype=np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "def bsearch_membership(csr_mat, row_ind, col_ind):\n",
    "    \"\"\" ehh, this is slower than `in`\n",
    "    csr_mat : interaction matrix\n",
    "    row_ind : user_ind\n",
    "    col_ind : item_ind\n",
    "    \"\"\"\n",
    "    start_idx = csr_mat.indptr[row_ind]\n",
    "    stop_idx = csr_mat.indptr[row_ind+1]\n",
    "    pos_vals = csr_mat.indices[start_idx:stop_idx]\n",
    "    insertion_index = bisect_left(pos_vals, col_ind)\n",
    "    return (insertion_index < (stop_idx-start_idx)) and (col_ind == pos_vals[insertion_index])\n",
    "\n",
    "def get_row_nz(csr_mat, col_ind):\n",
    "    \"\"\"faster than csr_mat.get_row for some reason\"\"\"\n",
    "    start_idx = csr_mat.indptr[col_ind]\n",
    "    stop_idx = csr_mat.indptr[col_ind+1]\n",
    "    return csr_mat.indices[start_idx:stop_idx]\n",
    "    \n",
    "\n",
    "# Negative sample generator\n",
    "\n",
    "def sample_neg(user_ind, interactions,\n",
    "               max_samples=100,\n",
    "               violating_cond=lambda neg_item_ind:True):\n",
    "    # Given a user index, sample a negative item\n",
    "#     user_pos_item_inds = interactions.getrow(user_ind).nonzero()[1]  # much too slow\n",
    "    user_pos_item_inds = get_row_nz(interactions, user_ind)\n",
    "    \n",
    "    n_sampled = 0\n",
    "    while n_sampled < max_samples:\n",
    "        neg_item_ind = np.random.randint(0, n_items)\n",
    "        n_sampled += 1\n",
    "        if neg_item_ind not in user_pos_item_inds:\n",
    "            if violating_cond(neg_item_ind):\n",
    "                break  # will go and use this sample\n",
    "    return neg_item_ind, n_sampled\n",
    "\n",
    "\n",
    "def violation_warp(neg_item_ind, user_tensor, pos_score, net):\n",
    "    items_input = Variable(torch.LongTensor([neg_item_ind]))\n",
    "    neg_score = net.predict_score(user_tensor, items_input)\n",
    "    condition_var = neg_score > pos_score - 1.\n",
    "    # Need to extract the data from the Var for logical bool\n",
    "    return torch.max(condition_var.data)\n",
    "\n",
    "\n",
    "def sample_warp(interactions, net):\n",
    "    nnz_users, nnz_items = map(np.int64, interactions.nonzero())\n",
    "    user_input = Variable(torch.LongTensor(nnz_users))\n",
    "    pos_item_input = Variable(torch.LongTensor(nnz_items))\n",
    "    pos_scores = net.predict_score(user_input, pos_item_input)\n",
    "    \n",
    "    nid_preload = []\n",
    "    n_sampled_preload = []\n",
    "    for uid, user_tensor, pos_score in zip(nnz_users, user_input, pos_scores):\n",
    "        nid, nsamp = sample_neg(\n",
    "            uid, interactions, \n",
    "            violating_cond=partial(violation_warp, \n",
    "                                   user_tensor=user_tensor, \n",
    "                                   pos_score=pos_score, \n",
    "                                   net=net))\n",
    "        nid_preload.append(nid)\n",
    "        n_sampled_preload.append(nsamp)\n",
    "        \n",
    "    return nid_preload, n_sampled_preload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.13 s, sys: 84 ms, total: 7.22 s\n",
      "Wall time: 4.52 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Sample from training interactions\n",
    "nnz_users, nnz_items = map(np.int64, train.nonzero())\n",
    "\n",
    "shuffle_ind = np.arange(len(nnz_users))\n",
    "\n",
    "# preload at the start of every epoch\n",
    "# (next epoch can be preloaded using cpu while gpu trains if the net is shared)\n",
    "nid_preload, n_sampled_preload = sample_warp(train, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\t\tAUC: train:0.804675422952\t test:0.698668994468\n",
      "avg nsamp:1.10856410051 \t time:5.12060308456\n",
      "Epoch 1\t\tAUC: train:0.908110871777\t test:0.828589238891\n",
      "avg nsamp:7.65719552759 \t time:24.3163590431\n",
      "Epoch 2\t\tAUC: train:0.933084519728\t test:0.85752300792\n",
      "avg nsamp:21.0292149241 \t time:64.241286993\n",
      "Epoch 3\t\tAUC: train:0.945215041587\t test:0.869739011746\n",
      "avg nsamp:25.2253837214 \t time:76.6893680096\n",
      "Epoch 4\t\tAUC: train:0.953289733134\t test:0.879337713435\n",
      "avg nsamp:27.0332024206 \t time:81.804019928\n",
      "Epoch 5\t\tAUC: train:0.958571955284\t test:0.885195985652\n",
      "avg nsamp:31.1956077426 \t time:94.1827380657\n",
      "Epoch 6\t\tAUC: train:0.961578843569\t test:0.887316457402\n",
      "avg nsamp:34.4481825833 \t time:103.758337021\n",
      "Epoch 7\t\tAUC: train:0.963488563086\t test:0.887488449733\n",
      "avg nsamp:36.0002805274 \t time:108.203058004\n",
      "Epoch 8\t\tAUC: train:0.964939686769\t test:0.887765256806\n",
      "avg nsamp:36.9745120827 \t time:111.449014902\n",
      "Epoch 9\t\tAUC: train:0.966455853553\t test:0.888851915736\n",
      "avg nsamp:37.5568468721 \t time:112.421780109\n",
      "Epoch 10\t\tAUC: train:0.967944402834\t test:0.890362541264\n",
      "avg nsamp:38.4306496213 \t time:116.653550863\n",
      "Epoch 11\t\tAUC: train:0.968946780845\t test:0.891403077822\n",
      "avg nsamp:39.3579128762 \t time:118.494557858\n",
      "Epoch 12\t\tAUC: train:0.969556810722\t test:0.891848578544\n",
      "avg nsamp:40.1447922094 \t time:120.793145895\n",
      "Epoch 13\t\tAUC: train:0.96994517488\t test:0.892080545459\n",
      "avg nsamp:41.0301767323 \t time:123.162359953\n",
      "Epoch 14\t\tAUC: train:0.970501547087\t test:0.892816023373\n",
      "avg nsamp:41.284635114 \t time:124.558209181\n",
      "Epoch 15\t\tAUC: train:0.971118262997\t test:0.89341801622\n",
      "avg nsamp:41.5250070132 \t time:125.504401922\n",
      "Epoch 16\t\tAUC: train:0.971521292954\t test:0.893730041255\n",
      "avg nsamp:41.7427964573 \t time:125.962660074\n",
      "Epoch 17\t\tAUC: train:0.971888639416\t test:0.893763893325\n",
      "avg nsamp:41.7370456458 \t time:125.171706915\n",
      "Epoch 18\t\tAUC: train:0.972266572454\t test:0.893594777776\n",
      "avg nsamp:42.2136416463 \t time:126.17987895\n",
      "Epoch 19\t\tAUC: train:0.972759716207\t test:0.893595074956\n",
      "avg nsamp:42.3992706288 \t time:128.103173971\n",
      "CPU times: user 33min 59s, sys: 2.08 s, total: 34min 1s\n",
      "Wall time: 34min 2s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "num_epochs = 20\n",
    "avg_nsamps = []\n",
    "tocs = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Epoch %d' % epoch, end='\\t')\n",
    "    tic = time()\n",
    "    \n",
    "    # Resample negs per pos interaction\n",
    "    nid_preload, n_sampled_preload = map(np.array, sample_warp(train, net))\n",
    "\n",
    "    np.random.shuffle(shuffle_ind)\n",
    "\n",
    "    uid_gen = batcher(nnz_users[shuffle_ind], batch_size)\n",
    "    pid_gen = batcher(nnz_items[shuffle_ind], batch_size)\n",
    "    nid_gen = batcher(nid_preload[shuffle_ind], batch_size)\n",
    "    n_samp_gen = batcher(n_sampled_preload[shuffle_ind], batch_size)\n",
    "    avg_nsamps_b = []\n",
    "    for uid_batch, pid_batch, nid_batch, nsamp_batch in zip(uid_gen, pid_gen, nid_gen, n_samp_gen):\n",
    "        user_input = Variable(torch.LongTensor(uid_batch))\n",
    "        p_item_input = Variable(torch.LongTensor(pid_batch))\n",
    "        n_item_input = Variable(torch.LongTensor(nid_batch))\n",
    "        nsamp_input = Variable(torch.FloatTensor(nsamp_batch))\n",
    "        pos_pred, neg_pred = net(user_input, p_item_input, n_item_input)\n",
    "        loss = criterion(pos_pred, neg_pred, nsamp_input)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        avg_nsamps_b.append(nsamp_batch)\n",
    "        \n",
    "    toc = time() - tic\n",
    "    avg_nsamps.append(np.mean(list(chain(*avg_nsamps_b))))\n",
    "    tocs.append(toc)\n",
    "    \n",
    "    print('AUC: train:{}\\t test:{}'\\\n",
    "          .format(metrics.full_auc_pytorch(net, train),\n",
    "                  metrics.full_auc_pytorch(net, test),\n",
    "                 ))\n",
    "    \n",
    "    print('avg nsamp:{} \\t time:{}'.format(avg_nsamps[-1], tocs[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f0d83fe7c90>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEDCAYAAAA7jc+ZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\npMgp6EVEitz/DysIAKRxKKqzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0d83fe7210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(num_epochs), tocs)\n",
    "plt.plot(range(num_epochs), avg_nsamps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
